{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP6sClrt+/EH5ZYVuJqgojq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["<a href=\"https://colab.research.google.com/github/arminnorouzi/machine_learning_course_UofA_MECE610/blob/main/L04_Deep_Learning_with_TensorFlow/L04c_Recurrent_Neural_Networks_with_TennsorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"],"metadata":{"id":"MLKwCEz-3d0q"}},{"cell_type":"markdown","source":["   # Recurrent Neural Networks (RNN) using TensorFlow\n","   \n","   - Developed by **Armin Norouzi**\n","   - Compatible with Google Colaboratory- Tensorflow 2.8.2\n","\n","   \n","   - **Objective:** Modeling time series estimation\n","   \n","   \n","**Table of content:**\n","\n","- Linear Regression with PyTorch\n","- Neural Network Basic Modeling using PyTorch\n","- Adavnced ANN Model for Regression\n","- Adavnced ANN Model for Classification\n","\n","\n","\n","\n"],"metadata":{"id":"Hc5RiwiU-4WM"}},{"cell_type":"markdown","source":["## Introduction to Trasnfer Learning (NLP)"],"metadata":{"id":"YmoM5bVxmXAX"}},{"cell_type":"markdown","source":["The main goal of [natural language processing (NLP)](https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32) is to derive information from natural language.\n","\n","Natural language is a broad term but you can consider it to cover any of the following:\n","* Text (such as that contained in an email, blog post, book, Tweet)\n","* Speech (a conversation you have with a doctor, voice commands you give to a smart speaker)\n","\n","Under the umbrellas of text and speech there are many different things you might want to do.\n"],"metadata":{"id":"aWafGPEt3h-y"}},{"cell_type":"markdown","source":["### Helper Function\n","\n","These functions developed in previous lectures"],"metadata":{"id":"LSMg5LWz4bC3"}},{"cell_type":"code","source":["# Create function to unzip a zipfile into current working directory \n","# (since we're going to be downloading and unzipping a few files)\n","import zipfile\n","\n","def unzip_data(filename):\n","  \"\"\"\n","  Unzips filename into the current working directory.\n","  Args:\n","    filename (str): a filepath to a target zip folder to be unzipped.\n","  \"\"\"\n","  zip_ref = zipfile.ZipFile(filename, \"r\")\n","  zip_ref.extractall()\n","  zip_ref.close()"],"metadata":{"id":"MuwAOCIx3hgC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the validation and training data separately\n","import matplotlib.pyplot as plt\n","\n","def plot_loss_curves(history):\n","  \"\"\"\n","  Returns separate loss curves for training and validation metrics.\n","  Args:\n","    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n","  \"\"\" \n","  loss = history.history['loss']\n","  val_loss = history.history['val_loss']\n","\n","  accuracy = history.history['accuracy']\n","  val_accuracy = history.history['val_accuracy']\n","\n","  epochs = range(len(history.history['loss']))\n","\n","  # Plot loss\n","  plt.plot(epochs, loss, label='training_loss')\n","  plt.plot(epochs, val_loss, label='val_loss')\n","  plt.title('Loss')\n","  plt.xlabel('Epochs')\n","  plt.legend()\n","\n","  # Plot accuracy\n","  plt.figure()\n","  plt.plot(epochs, accuracy, label='training_accuracy')\n","  plt.plot(epochs, val_accuracy, label='val_accuracy')\n","  plt.title('Accuracy')\n","  plt.xlabel('Epochs')\n","  plt.legend();"],"metadata":{"id":"9khSwzv23haK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create tensorboard callback (functionized because need to create a new one for each model)\n","import datetime\n","import tensorflow as tf\n","\n","def create_tensorboard_callback(dir_name, experiment_name):\n","  ''' This function is used to create tensorboard callback\n","\n","  Arg:\n","      dir_name: overall logs directory\n","      experiment_name: particular experiment\n","      current_timestamp: time the experiment started based on Python's datetime.datetime().now()\n","  '''\n","  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") \n","  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n","      log_dir=log_dir\n","  )\n","  print(f\"Saving TensorBoard log files to: {log_dir}\")\n","  return tensorboard_callback"],"metadata":{"id":"ex4WlQQVahTb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def compare_historys(original_history, new_history, initial_epochs=5):\n","    \"\"\"\n","    Compares two TensorFlow model History objects.\n","    \n","    Args:\n","      original_history: History object from original model (before new_history)\n","      new_history: History object from continued model training (after original_history)\n","      initial_epochs: Number of epochs in original_history (new_history plot starts from here) \n","    \"\"\"\n","    \n","    # Get original history measurements\n","    acc = original_history.history[\"accuracy\"]\n","    loss = original_history.history[\"loss\"]\n","\n","    val_acc = original_history.history[\"val_accuracy\"]\n","    val_loss = original_history.history[\"val_loss\"]\n","\n","    # Combine original history with new history\n","    total_acc = acc + new_history.history[\"accuracy\"]\n","    total_loss = loss + new_history.history[\"loss\"]\n","\n","    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n","    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n","\n","    # Make plots\n","    plt.figure(figsize=(8, 8))\n","    plt.subplot(2, 1, 1)\n","    plt.plot(total_acc, label='Training Accuracy')\n","    plt.plot(total_val_acc, label='Validation Accuracy')\n","    plt.plot([initial_epochs-1, initial_epochs-1],\n","              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n","    plt.legend(loc='lower right')\n","    plt.title('Training and Validation Accuracy')\n","\n","    plt.subplot(2, 1, 2)\n","    plt.plot(total_loss, label='Training Loss')\n","    plt.plot(total_val_loss, label='Validation Loss')\n","    plt.plot([initial_epochs-1, initial_epochs-1],\n","              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n","    plt.legend(loc='upper right')\n","    plt.title('Training and Validation Loss')\n","    plt.xlabel('epoch')\n","    plt.show()\n","  "],"metadata":{"id":"RyPBrBAS3hXi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load and prepare data"],"metadata":{"id":"k9AvF7VqIn0W"}},{"cell_type":"markdown","source":["### Download data"],"metadata":{"id":"fvEAxfODNI6e"}},{"cell_type":"markdown","source":["\n","\n","Let's start by download a text dataset. We'll be using the [Real or Not?](https://www.kaggle.com/c/nlp-getting-started/data) datset from Kaggle which contains text-based Tweets about natural disasters. The original downloaded data has not been altered to how you would download it from Kaggle:\n","\n","* `sample_submission.csv` - an example of the file you'd submit to the Kaggle competition of your model's predictions.\n","* `train.csv` - training samples of real and not real diaster Tweets.\n","* `test.csv` - testing samples of real and not real diaster Tweets."],"metadata":{"id":"S1UkOUOvInlW"}},{"cell_type":"code","source":["# Turn .csv files into pandas DataFrame's\n","import pandas as pd\n","train_df = pd.read_csv(\"https://raw.githubusercontent.com/arminnorouzi/machine_learning_course_UofA_MECE610/main/Data/NLP_train.csv\")\n","train_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"66RSpEPKJ0PM","executionInfo":{"status":"ok","timestamp":1662670544195,"user_tz":240,"elapsed":586,"user":{"displayName":"Armin Norouzi Yengeje","userId":"07700221665224727665"}},"outputId":"19637198-274a-4950-8915-9b077db295e0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id keyword location                                               text  \\\n","0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n","1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n","2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n","3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n","4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n","\n","   target  \n","0       1  \n","1       1  \n","2       1  \n","3       1  \n","4       1  "],"text/html":["\n","  <div id=\"df-7e653a80-33e9-4bf7-946a-32ab1a8eae57\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Our Deeds are the Reason of this #earthquake M...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Forest fire near La Ronge Sask. Canada</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>All residents asked to 'shelter in place' are ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>13,000 people receive #wildfires evacuation or...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7e653a80-33e9-4bf7-946a-32ab1a8eae57')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7e653a80-33e9-4bf7-946a-32ab1a8eae57 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7e653a80-33e9-4bf7-946a-32ab1a8eae57');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["test_df = pd.read_csv(\"https://raw.githubusercontent.com/arminnorouzi/machine_learning_course_UofA_MECE610/main/Data/NLP_test.csv\")\n","test_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"roDE7Jaa3hVC","executionInfo":{"status":"ok","timestamp":1662670544396,"user_tz":240,"elapsed":203,"user":{"displayName":"Armin Norouzi Yengeje","userId":"07700221665224727665"}},"outputId":"de213071-3665-424a-a509-84527a869592"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id keyword location                                               text\n","0   0     NaN      NaN                 Just happened a terrible car crash\n","1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n","2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n","3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n","4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"],"text/html":["\n","  <div id=\"df-17a207ad-3eb7-4f72-a312-08ac3d20a113\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>keyword</th>\n","      <th>location</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Just happened a terrible car crash</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Heard about #earthquake is different cities, s...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>there is a forest fire at spot pond, geese are...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Apocalypse lighting. #Spokane #wildfires</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>11</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17a207ad-3eb7-4f72-a312-08ac3d20a113')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-17a207ad-3eb7-4f72-a312-08ac3d20a113 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-17a207ad-3eb7-4f72-a312-08ac3d20a113');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":[],"metadata":{"id":"PPjX_H6-Uy24"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LkUBhop7Uy0w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oST2K_3bUyx7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"y4iUoMqeUyvJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Z7PWDj88Uysf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sIB3aNUwUyp6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wp1E9Q8TUyne"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Kp_dds_FUyks"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vMUSlBeeUyh1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pDDkS0MKUyfI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1_hgn7lUUycl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iiIQ4SboUyZj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lCmc9AC2UyWb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pLrqaBhpUyTk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"3qtPM_ipUyRT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iIL-5BnPUyOS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"W88c5pwEUyL8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"V0fZqE2UUyJV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lto9SIpFUyGK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dVmCiL-mUyDL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5sEzjUUWUyAh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"dL7jhGvOUx9x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Vu_PQ8R2Ux65"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"QBeELc56Ux4B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"nqtQzMSbUx1R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"yB4ALuSyUxyT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"v8aMXBNMUxvY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"reSSEBy3Uxsx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"GlVEov29Uxm0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"cgyVU-s-UxV5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## References: \n","\n","* [A Simple Introduction to Natural Language Processing](https://becominghuman.ai/a-simple-introduction-to-natural-language-processing-ea66a1747b32)\n","* [How to solve 90% of NLP problems: a step-by-step guide](https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e)\n","* [TensorFlow Transfer Learning Guide](https://www.tensorflow.org/tutorials/images/transfer_learning)\n","* [Transfer Learning with TensorFlow Hub tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning_with_hub)\n","* [fine-tuning a TensorFlow Hub model tutorial](https://www.tensorflow.org/hub/tf2_saved_model#fine-tuning) \n","* [experiment tracking with Weights & Biases](https://www.wandb.com/experiment-tracking)"],"metadata":{"id":"S03Aq8gplF23"}},{"cell_type":"code","source":[],"metadata":{"id":"D2gd-EIq2mvn"},"execution_count":null,"outputs":[]}]}